\documentclass{article}

\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{amsmath}
\include{macros}

\title{Bone Cement Volumetry in sagittal and axial MRT-Images of the Spine}

\author{Friederici Anke\\ Jordan Grigori}

\begin{document}
  
  \begin{titlepage}
    \centering
    
  \end{titlepage}
  
  \maketitle
  \thispagestyle{empty}
  \pagebreak
  
  \section{Introduction}
  \setcounter{page}{1}
  {
    We were introduced to the problem of semiautomatic bone cement volumetry 
    on MR-images of a spline.
    Our application is required 
    to detect such regions of the spine reliably to allow for volumetric measurements.\\
    \\The data that is given presents the challenge, MR-images, which do not have
    the strong contrast of CT-images nor are as noise free as CT-images, when it
    comes to bone tissue. Thus more image processing becomes necessary to possibly 
    achieve equally as good result as working with CT data.
    At its core this is a non trivial segmentation task, which requires a thought 
    through choice of image processing and segmentation algorithms.\\
    \\Our approach was to split the solution to the problem in two steps:
    \begin{enumerate}
      \item Single out one vertebra of choice, by user input (e.g. a single mouse click).
      \item Segment the chosen vertebra to its extent over the MR-images and measure the hollow regions volume, as precise as possible.
    \end{enumerate}
    We decided to keep it as simple as possible, by implementing the task at hand 
    entirely on Matlab. 
    As we are faced with possibly very uncommonly-shaped regions, we chose 'Normalized Graph Cuts' \cite{[ShiMalik00]} as our segmentation algorithm.
    It is heavily based on matrix operations and does not enforce any 'roundness' of the result.
    \\Matlab also has its own implementation of an active contour
    operation \cite{[ChanVese01]}, which could be used to segment the vertebra needed to a satisfying degree for the actual task of bone cement volumetry.\\	
    \\In the following chapters we will first describe how we implemented the vertebra segmentation.
    Afterwards, we will move on to describing our chosen filling compound segmentation inside the vertebra.
    At last in the remaining two chapters we will present our results and evaluate them, to see how well our application fare against the ground truth solution.
    on MR-images of a spline.
    Our application is required 
    to detect such regions of the spine reliably to allow for volumetric measurements.\\
    \\The data that is given presents the challenge, MR-images, which do not have
    the strong contrast of CT-images nor are as noise free as CT-images, when it
    comes to bone tissue. Thus more image processing becomes necessary to possibly 
    achieve equally as good result as working with CT data.
    At its core this is a non trivial segmentation task, which requires a thought 
    through choice of image processing and segmentation algorithms.\\
    \\Our approach was to split the solution to the problem in two steps:
    \begin{enumerate}
      \item Single out one vertebra of choice, by user input (e.g. a single mouse click).
      \item Segment the chosen vertebra to its extent over the MR-images and measure the hollow regions volume, as precise as possible.
    \end{enumerate}
    We decided to keep it as simple as possible, by implementing the task at hand 
    entirely on Matlab. 
    As we are faced with possibly very uncommonly-shaped regions, we chose 'Normalized Graph Cuts' \cite{[ShiMalik00]} as our segmentation algorithm.
    It is heavily based on matrix operations and does not enforce any 'roundness' of the result.
    \\Matlab also has its own implementation of an active contour
    operation \cite{[ChanVese01]}, which could be used to segment the vertebra needed to a satisfying degree for the actual task of bone cement volumetry.\\	
    \\In the following chapters we will first describe how we implemented the vertebra segmentation.
    Afterwards, we will move on to describing our chosen filling compound segmentation inside the vertebra.
    At last in the remaining two chapters we will present our results and evaluate them, to see how well our application fare against the ground truth solution.
  }
  \pagebreak
  \section{Vertebra Segmentation}
  {
    The implementation of the vertebra segmentation makes solely use of features and algorithms
    of Matlab. At first we let the user select a vertebra interactively. For that purpose a basic 
    dicom slice viewer is available, to first let the user decide, which slide he sees fitting to select the ROI. In the next step via, currently two clicks, the user chooses at last the ROI, marking the left upper and the right lower region of the desired vertebra.\\
    \\In the next stage the actual vertebra segmentation takes place, using the 'Chan-Vese Segmentation' \cite{[ChanVese01]}, which is an active contour algorithm without edges. It is based on a simplified 'Mumford-Shah Model', it requires the approximated function to be piecewise constant instead of smooth and further more results in a binary approximation. The segmentation boundary is represented implicitly with a level set function, which is found by a gradient descent. \\
    \\ The Matlab implementation of this algorithm provides one parameter, the 'SmoothFactor', which allows us to control the shape of the resulting segmentation.
    Low values of 'SmoothFactor', below 1.5, allow for finer details to come through, whereas higher values might smooth over details. For our purpose 3.0 was the value of choice for the 'SmoothFactor' parameter, to achieve satisfying vertebra segmentation results.\\
    \\For improved vertebra segmentation the T1 plus contrast-agent and T2 MR-sequences are used, by obtaining a segmentation mask with the 'Chan-Vese Segmentation' \cite{[ChanVese01]} on each corresponding user chosen MR-slice. Multiplying both obtained mask results in a satisfactory segmentation of the vertebra.  
    In order to obtain the remaining masks on the MR-sequence, containing the chosen vertebra and make volumetric measurement of bone cement treatment region possible we apply the 'Chan-Vese Segmentation' \cite{[ChanVese01]} on each MR-slice. \newline 
    We do it in two ways, away from the initially chosen slice. In this process the input mask for the current slice to apply the segmentation algorithm on is the one of its predecessor relative to the initially chosen slice and the 'processing direction'.
    \begin{figure}[h]
      \centering
      \begin{subfigure}[t]{0.45\linewidth}
        \centering
        \includegraphics[scale=1.4]{VertebraSegmentationExample_1.png}
        
      \end{subfigure}
      \hfill
      \begin{subfigure}[t]{0.45\linewidth}
        \centering
        \includegraphics[scale=0.4]{VertebraSegmentationExample_2.png}
      \end{subfigure}
      \caption{Vertebra Segmentation Example\\
        The segmented area containing the cement region is highlighted in red. For further processing, the data is shrunk to the minimal box enclosing the mask.}
    \end{figure} 
    The implementation of the vertebra segmentation makes solely use of features and algorithms
    of Matlab. At first we let the user select a vertebra interactively. For that purpose a basic 
    dicom slice viewer is available, to first let the user decide, which slide he sees fitting to select the ROI. In the next step via, currently two clicks, the user chooses at last the ROI, marking the left upper and the right lower region of the desired vertebra.\\
    \\In the next stage the actual vertebra segmentation takes place, using the \textit{Chan-Vese Segmentation} \cite{[ChanVese01]}, which is an active contour algorithm without edges. It is based on a simplified \textit{Mumford-Shah Model} \cite{[MumfordShah89]}, it requires the approximated function to be piecewise constant instead of smooth and further more results in a binary approximation. The segmentation boundary is represented implicitly by a level set function. The contour of the segmentation is iteratively found by a gradient descent. \\
    \\ The Matlab implementation of this algorithm provides two parameters, the first one, 'SmoothFactor', which allows us to control the shape of the resulting segmentation and the second being the count of iterations for the evolution of the contour.
    Low values of 'SmoothFactor', below 0, allow for finer details to come through, whereas higher values might smooth over details. For our purpose 3.0 was the value of choice for the 'SmoothFactor' parameter and a count of 200 for the iterations, to achieve satisfying vertebra segmentation results.\\
    \\For improved vertebra segmentation the T1 plus contrast-agent and T2 MR-sequences are used, by obtaining a segmentation mask with the \textit{Chan-Vese Segmentation} \cite{[ChanVese01]} on each corresponding user chosen MR-slice. Multiplying both obtained mask results in a satisfactory segmentation of the vertebra.  
    Initially in order to obtain the remaining masks on the MR-sequence, containing the chosen vertebra and make volumetric measurement of bone cement treatment region possible we applied the \textit{Chan-Vese Segmentation} \cite{[ChanVese01]} on each MR-slice. \newline 
    We did it in two ways, away from the initially chosen slice. In this process the input mask for the current slice to apply the segmentation algorithm on is the one of its predecessor relative to the initially chosen slice and the 'processing direction'.
    Unfortunately the results of successive application of the described scheme were highly inaccurate on not vertically aligned, slightly rotated slices.\\
    \\In the end a simpler solution was implemented, using the same fist result mask for each MR-slice. Unfortunately it also could not be achieved to reduce the user interaction to only one click due otherwise poor results with the \textit{Chan-Vese Segmentation}. 
    \begin{figure}[h]
      \centering
      \begin{subfigure}[t]{0.45\linewidth}
        \centering
        \includegraphics[scale=1.4]{VertebraSegmentationExample_1.png}
        
      \end{subfigure}
      \hfill
      \begin{subfigure}[t]{0.45\linewidth}
        \centering
        \includegraphics[scale=0.4]{VertebraSegmentationExample_2.png}
      \end{subfigure}
      \caption{Vertebra Segmentation Example\\
        The segmented area containing the cement region is highlighted in red. For further processing, the data is shrunk to the minimal box enclosing the mask.}
    \end{figure} 
  }	
  
  \pagebreak
  \section{Filling Compound Segmentation}
  
  Within this rough segmentation of the vertebra body, we now search for the bone cement structures.
  In this reduced dataset, we are faced with a relatively low resolution (approximately $50 \times 40$ pixels $\times 15$ slices), high inhomogeneities due to the porous structure of bones and irregular structures to be segmented.
  The holes filled with bone cement show as low-valued areas.
  Due to partial volume effects, the edges are not sharp. 
  
  Taking all this together, we decided to try \textit{Normalized Graph Cuts} as described by Shi and Malik~\cite{[ShiMalik00]} as segmentation algorithm.
  Basically, the image is represented as a non-directed, weighted graph, with pixels and inter-pixel similarities corresponding to nodes and weights respectively.
  Representing the graph to a Laplacian matrix, we are able to compute the \textit{real-valued minimal normalized cut} by solving an eigenvector problem on a similarity graph.
  
  \subsection*{Normalized Graph Cut}
    For computation, we set up
    
  \begin{equation*}
  \begin{alignedat}{2}
  \mW_{ij} &= w_{ij} \\
  \mD_{ii} &= \sum_j w_{ij} .
  \end{alignedat}
  \end{equation*}
  $\mW$ is the connectivity matrix, symmetric semi-positive definite by construction.
  $\mD$ is a diagonal matrix storing the total connectivity per point.
  The weights $w_{ij}$ are to be filled with a measure of similarity.
  This is basically the only tunable parameter of the method.
  
  The \textit{normalized cut} of two segments A and B is defined as the connectivity between A and B, normalized by the total connectivity of each segment, or
  \begin{equation}\label{eq:mincut}
    \frac{\sum_{a \in A,b \ in B} w_{ab}}
    {\sum_{a \in A, v \in A \cup B} w_{av}} + 
      \frac{\sum_{a \in A,b \ in B} w_{ab}}
      {\sum_{b \in B, v \in A \cup B} w_{bv}}
  \end{equation}
 
  
  Based on $\mW$ and $\mD$, the \textit{real-valued minimal normalized cut} of the graph can be found by solving
  \begin{equation}
    (\mD-\mW) y = \lambda \mD y
  \end{equation}
  for minimal $y$, \ie by solving a Laplacian matrix for the eigenvector with the smallest corresponding eigenvalue (omitting the first eigenvector-eigenvalue pair, $\{\textbf{1}, 0\}$).
  This $y_{min}$ will have the property of minimizing the total cut, where $1$ and $-1$ indicate the two segments.
  %each value represents the affiliation to the $1$ or $-1$ segment.
  To extract the optimal \textit{binary} segmentation from this field, Shi and Malik suggest to simply try out several threshold values on $y_{min}$ and applying the one minimizing equation \ref{eq:mincut}.
  
  \subsection*{Connectivity Matrix Setup}
  As mentioned above, the only exchangeable parameter in the method is $w_{ij}$, the similarity between pixels.
  We followed the example given by Shi and Malik. Within a set neighborhood, similarity is defined as difference in value divided by distance:
  \begin{equation}
    w_{ij} = \frac{1}{dist(i,j)}~
    e^{\frac{-\Norm{X_i - X_j}^2}{\sigma^2_X}}
  \end{equation}
  where $X_i$ is the image value at position $i$ and $\sigma^2_X$ is the overall variance of all $X_i$.
  We chose a neighborhood of up to $8$ pixels in each direction and up to $\lceil\frac{8}{6}\rceil=2$ slices to account for the difference in element distance.
  More neighbors add more non-zero values to $\mW$, but do not increase its size. So, as solving becomes slower, it is also stabilized.
  
  \subsection{Iterative Segmentation}
  As the matrices involved are symmetric, all eigenvalues are orthogonal.
  This means that while the second smallest eigenvalue can be used to cut the area in half, the next eigenvectors cut the resulting segments optimally again.
  Shi and Malik mention the instability of this approach.
  Cuts become more expensive and less accurate the higher the eigenvalue gets.
  
  Taking this into account, we implemented 4 different possibilities for iterative segmentation:
  \begin{enumerate}
    \item
    Using the $n$ smallest eigenvalues, the area is segmented into approximately $2^n$ segments.
    This variant results in several small segments and performs worse the higher $n$ becomes.
    For $n = 1$, only one cut is performed, which is the basis for the other versions.
    \item
    Instead of solving the system once for $n$ eigenvalues, we can also recursively subdivide the segments.
    This basically means computing eigenvalues of a submatrix and evaluating equation \ref{eq:mincut} in a smaller area.
    However, the segments will not always be of the same size, result in segments of highly varying size.
    \item
    To circumvent this problem, one can always split the segment with the highest area, until a certain segment size or iteration count is reached.
    This however tends to cut uniform areas more often than necessary, while interesting areas tend to have a smaller area.
    \item
    In order to integrate this property, we decided to choose the segment with highest variance as splitting candidate.
    To ignore high variances in higher image values, we clamp them to approximately double the highest cement value.
  \end{enumerate}
  
  As we can reuse the system matrix in all cases, they are not considerably different in computational complexion.
  The first version is the most simple and slightly faster (as we do not need to partition the system and only once split non-connected regions with the same segment ID).
  The recursive variant is outperformed by both the equal area and minimal variance criterion.
  We further observed the cement regions to be rather small compared to the complete vertebra, and thus favor the fourth variance-based approach.
  
  The beauty lies in the applicability of the approach to different inputs, in our case 2D and 3D images.
  We were easily able to develop and debug on 2D images, as the extension to 3D could be achieved with a larger neighborhood and adjustments in the visualization.
  
  
  \section{Results}
  {
    \begin{figure}[h]
      \centering
      \begin{subfigure}[t]{0.45\linewidth}
        \centering
        \includegraphics{test.png}
        \caption{Subfigures \textit{woopwoop}}
      \end{subfigure}
      \hfill
      \begin{subfigure}[t]{0.45\linewidth}
        \centering
        \includegraphics{test.png}
        \caption{Another really awesome image}
      \end{subfigure}
      \caption{These are some awesome images}
    \end{figure}
  }
  \pagebreak
  \section{Evaluation}
  
  
  \begin{thebibliography}{9}
    
    \bibitem{[ChanVese01]}
    T. F. Chan and L. A. Vese,
    \emph{"Active contours without edges", IEEE Transactions on Image Processing},
    vol. 10, Issue 2, pp. 266-277, 2001.
    
    
    \bibitem{[ShiMalik00]}
    J.  Shi  and  J.  Malik,
    \emph{"Normalized Cuts and Image Segmentation", IEEE Transactions on Pattern Analysis and Machine Intelligence},
    vol. 22, pp.888-904,
    2000.
    
    \bibitem{[MumfordShah89]}
    D. Mumford and J. Shah,
    \emph{Optimal approximation by piecewise smooth functions and associated
      variational problems," Communications on Pure and Applied Mathematics},
    vol. 42, pp. 577-685,,
    1989.
    
  \end{thebibliography}
  
\end{document}